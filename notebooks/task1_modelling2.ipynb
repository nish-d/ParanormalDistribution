{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/var/folders/32/zv3nm8_12xb9ytd7vk7nnr6w0000gn/T/ipykernel_47053/74542634.py:7: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, f1_score\n",
    "from sklearn import preprocessing\n",
    "from pandas import MultiIndex, Int64Index\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import optuna\n",
    "import pandas as pd\n",
    "from sklearn import ensemble\n",
    "from sklearn import datasets\n",
    "from sklearn import model_selection\n",
    "\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "import autogluon.core as ag\n",
    "from sklearn.model_selection import train_test_split\n",
    "import bokeh\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install xgboost\n",
    "#!pip3 install optuna\n",
    "#!pip install autogluon --upgrade\n",
    "# !pip install optuna\n",
    "# !pip install scipy\n",
    "# !pip install autogluon\n",
    "# !pip install xgboost\n",
    "# !python3.9 -m pip install --upgrade pip\n",
    "#!pip install bokeh==2.0.1\n",
    "#!pip install jupyter --upgrade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../data/train_encoded_1.csv')\n",
    "df_test = pd.read_csv('../data/test_encoded_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "train, valid = train_test_split(df_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = df_train.drop(['price', 'size_sqft'], axis=1)\n",
    "X_train = train.drop(['price', 'size_sqft'], axis=1)\n",
    "\n",
    "X_valid = valid.drop(['price', 'size_sqft'], axis=1)\n",
    "y_valid = valid['price_per_sqft']\n",
    "\n",
    "df_test_size_sqft = df_test['size_sqft'].copy()\n",
    "df_test= df_test.drop(['size_sqft'], axis=1)\n",
    "\n",
    "metric_reg = 'mean_absolute_error'\n",
    "label_reg = 'price_per_sqft'\n",
    "train_data_reg = TabularDataset(X_train) \n",
    "valid_data_reg = TabularDataset(X_valid)\n",
    "test_data_reg = TabularDataset(df_test)\n",
    "combined = TabularDataset(combined)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tabular Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221028_023652/\"\n",
      "Presets specified: ['best_quality']\n",
      "Warning: hyperparameter tuning is currently experimental and may cause the process to hang.\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221028_023652/\"\n",
      "AutoGluon Version:  0.5.2\n",
      "Python Version:     3.9.15\n",
      "Operating System:   Darwin\n",
      "Train Data Rows:    18424\n",
      "Train Data Columns: 31\n",
      "Label Column: price_per_sqft\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (4525.797460167968, 461.7295308187673, 1811.07817, 965.70493)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "/usr/local/lib/python3.9/site-packages/autogluon/tabular/learner/default_learner.py:151: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  missinglabel_inds = [index for index, x in X[self.label].isna().iteritems() if x]\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    5969.89 MB\n",
      "\tTrain Data (Original)  Memory Usage: 4.57 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 14 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 15 | ['num_beds', 'num_baths', 'built_year', 'pri_sch', 'sec_sch', ...]\n",
      "\t\t('int', [])   : 16 | ['close_pri_sch', 'close_sec_sch', 'property_type_cluster house', 'property_type_condo', 'property_type_corner terrace', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 15 | ['num_beds', 'num_baths', 'built_year', 'pri_sch', 'sec_sch', ...]\n",
      "\t\t('int', [])       :  2 | ['close_pri_sch', 'close_sec_sch']\n",
      "\t\t('int', ['bool']) : 14 | ['property_type_cluster house', 'property_type_condo', 'property_type_corner terrace', 'property_type_executive condo', 'property_type_hdb', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t31 features in original data used to generate 31 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 2.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.23s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Excluded Model Types: ['FASTAI', 'KNN', 'RF', 'XGB']\n",
      "Fitting 3 L1 models ...\n",
      "Hyperparameter tuning model: LightGBMXT_BAG_L1 ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "923f836da0884999ba0af79d923b2974",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l1: 161.308\n",
      "[2000]\tvalid_set's l1: 157.268\n",
      "[3000]\tvalid_set's l1: 155.77\n",
      "[4000]\tvalid_set's l1: 154.747\n",
      "[5000]\tvalid_set's l1: 154.259\n",
      "[6000]\tvalid_set's l1: 153.845\n",
      "[7000]\tvalid_set's l1: 153.713\n",
      "[8000]\tvalid_set's l1: 153.731\n",
      "[9000]\tvalid_set's l1: 153.829\n",
      "[1000]\tvalid_set's l1: 152.737\n",
      "[2000]\tvalid_set's l1: 151.687\n",
      "[3000]\tvalid_set's l1: 151.331\n",
      "[4000]\tvalid_set's l1: 151.159\n",
      "[5000]\tvalid_set's l1: 151.209\n",
      "[1000]\tvalid_set's l1: 162.246\n",
      "[2000]\tvalid_set's l1: 157.808\n",
      "[3000]\tvalid_set's l1: 156.195\n",
      "[4000]\tvalid_set's l1: 155.429\n",
      "[5000]\tvalid_set's l1: 155.154\n",
      "[6000]\tvalid_set's l1: 155.117\n",
      "[7000]\tvalid_set's l1: 155.141\n",
      "[8000]\tvalid_set's l1: 155.121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitted model: LightGBMXT_BAG_L1/T1 ...\n",
      "\t-153.6036\t = Validation score   (-mean_absolute_error)\n",
      "\t11.64s\t = Training   runtime\n",
      "\t0.48s\t = Validation runtime\n",
      "Fitted model: LightGBMXT_BAG_L1/T2 ...\n",
      "\t-151.1279\t = Validation score   (-mean_absolute_error)\n",
      "\t12.0s\t = Training   runtime\n",
      "\t0.36s\t = Validation runtime\n",
      "Fitted model: LightGBMXT_BAG_L1/T3 ...\n",
      "\t-154.9918\t = Validation score   (-mean_absolute_error)\n",
      "\t16.03s\t = Training   runtime\n",
      "\t0.55s\t = Validation runtime\n",
      "Hyperparameter tuning model: ExtraTrees_BAG_L1 ...\n",
      "\tNo hyperparameter search space specified for ExtraTrees. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
      "Warning: Exception caused ExtraTrees_BAG_L1 to fail during hyperparameter tuning... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1380, in _train_single_full\n",
      "    hpo_models, hpo_results = model.hyperparameter_tune(\n",
      "  File \"/usr/local/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1001, in hyperparameter_tune\n",
      "    return self._hyperparameter_tune(hpo_executor=hpo_executor, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 182, in _hyperparameter_tune\n",
      "    return super()._hyperparameter_tune(X=X, y=y, k_fold=k_fold, hpo_executor=hpo_executor, preprocess_kwargs=preprocess_kwargs, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1080, in _hyperparameter_tune\n",
      "    model_path = model_info['path']\n",
      "TypeError: string indices must be integers\n",
      "string indices must be integers\n",
      "Hyperparameter tuning model: NeuralNetTorch_BAG_L1 ...\n",
      "Fitted model: NeuralNetTorch_BAG_L1/T1 ...\n",
      "\t-158.5397\t = Validation score   (-mean_absolute_error)\n",
      "\t57.09s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitted model: NeuralNetTorch_BAG_L1/T2 ...\n",
      "\t-153.6849\t = Validation score   (-mean_absolute_error)\n",
      "\t57.58s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitted model: NeuralNetTorch_BAG_L1/T3 ...\n",
      "\t-160.5432\t = Validation score   (-mean_absolute_error)\n",
      "\t135.87s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1/T1 ...\n",
      "\tWill use sequential fold fitting strategy because Darwin OS does not yet support parallel folding.\n",
      "\tFitting 7 child models (S1F2 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l1: 147.955\n",
      "[2000]\tvalid_set's l1: 144.087\n",
      "[3000]\tvalid_set's l1: 142.685\n",
      "[4000]\tvalid_set's l1: 142.201\n",
      "[5000]\tvalid_set's l1: 142.093\n",
      "[6000]\tvalid_set's l1: 142.112\n",
      "[7000]\tvalid_set's l1: 142.179\n",
      "[1000]\tvalid_set's l1: 148.792\n",
      "[2000]\tvalid_set's l1: 146.745\n",
      "[3000]\tvalid_set's l1: 146.16\n",
      "[4000]\tvalid_set's l1: 145.635\n",
      "[5000]\tvalid_set's l1: 145.596\n",
      "[6000]\tvalid_set's l1: 145.629\n",
      "[1000]\tvalid_set's l1: 156.044\n",
      "[2000]\tvalid_set's l1: 153.007\n",
      "[3000]\tvalid_set's l1: 152.175\n",
      "[4000]\tvalid_set's l1: 152.046\n",
      "[5000]\tvalid_set's l1: 151.865\n",
      "[6000]\tvalid_set's l1: 151.739\n",
      "[7000]\tvalid_set's l1: 151.712\n",
      "[8000]\tvalid_set's l1: 151.706\n",
      "[9000]\tvalid_set's l1: 151.71\n",
      "[1000]\tvalid_set's l1: 143.971\n",
      "[2000]\tvalid_set's l1: 140.902\n",
      "[3000]\tvalid_set's l1: 139.364\n",
      "[4000]\tvalid_set's l1: 138.986\n",
      "[5000]\tvalid_set's l1: 139.179\n",
      "[1000]\tvalid_set's l1: 154.494\n",
      "[2000]\tvalid_set's l1: 151.822\n",
      "[3000]\tvalid_set's l1: 150.864\n",
      "[4000]\tvalid_set's l1: 150.622\n",
      "[5000]\tvalid_set's l1: 150.591\n",
      "[1000]\tvalid_set's l1: 154.68\n",
      "[2000]\tvalid_set's l1: 150.882\n",
      "[3000]\tvalid_set's l1: 149.325\n",
      "[4000]\tvalid_set's l1: 148.524\n",
      "[5000]\tvalid_set's l1: 148.227\n",
      "[6000]\tvalid_set's l1: 147.805\n",
      "[7000]\tvalid_set's l1: 147.735\n",
      "[8000]\tvalid_set's l1: 147.63\n",
      "[9000]\tvalid_set's l1: 147.498\n",
      "[10000]\tvalid_set's l1: 147.445\n",
      "[1000]\tvalid_set's l1: 160.579\n",
      "[2000]\tvalid_set's l1: 155.308\n",
      "[3000]\tvalid_set's l1: 153.061\n",
      "[4000]\tvalid_set's l1: 152.091\n",
      "[5000]\tvalid_set's l1: 151.707\n",
      "[6000]\tvalid_set's l1: 151.369\n",
      "[7000]\tvalid_set's l1: 151.252\n",
      "[8000]\tvalid_set's l1: 151.264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-147.5876\t = Validation score   (-mean_absolute_error)\n",
      "\t79.74s\t = Training   runtime\n",
      "\t3.25s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1/T2 ...\n",
      "\tFitting 7 child models (S1F2 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l1: 140.476\n",
      "[1000]\tvalid_set's l1: 143.564\n",
      "[1000]\tvalid_set's l1: 149.148\n",
      "[2000]\tvalid_set's l1: 148.667\n",
      "[3000]\tvalid_set's l1: 148.629\n",
      "[1000]\tvalid_set's l1: 136.222\n",
      "[2000]\tvalid_set's l1: 135.872\n",
      "[1000]\tvalid_set's l1: 150.606\n",
      "[1000]\tvalid_set's l1: 146.707\n",
      "[2000]\tvalid_set's l1: 145.3\n",
      "[3000]\tvalid_set's l1: 145.305\n",
      "[1000]\tvalid_set's l1: 149.512\n",
      "[2000]\tvalid_set's l1: 148.869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-145.3685\t = Validation score   (-mean_absolute_error)\n",
      "\t60.48s\t = Training   runtime\n",
      "\t1.34s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1/T3 ...\n",
      "\tFitting 7 child models (S1F2 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l1: 147.092\n",
      "[2000]\tvalid_set's l1: 145.146\n",
      "[3000]\tvalid_set's l1: 144.425\n",
      "[4000]\tvalid_set's l1: 144.004\n",
      "[5000]\tvalid_set's l1: 144.139\n",
      "[1000]\tvalid_set's l1: 148.897\n",
      "[2000]\tvalid_set's l1: 147.117\n",
      "[3000]\tvalid_set's l1: 146.58\n",
      "[4000]\tvalid_set's l1: 146.391\n",
      "[5000]\tvalid_set's l1: 146.323\n",
      "[6000]\tvalid_set's l1: 146.569\n",
      "[1000]\tvalid_set's l1: 159.815\n",
      "[2000]\tvalid_set's l1: 156.356\n",
      "[3000]\tvalid_set's l1: 155.644\n",
      "[4000]\tvalid_set's l1: 154.986\n",
      "[5000]\tvalid_set's l1: 154.578\n",
      "[6000]\tvalid_set's l1: 154.348\n",
      "[7000]\tvalid_set's l1: 154.359\n",
      "[8000]\tvalid_set's l1: 154.346\n",
      "[9000]\tvalid_set's l1: 154.274\n",
      "[10000]\tvalid_set's l1: 154.369\n",
      "[1000]\tvalid_set's l1: 143.521\n",
      "[2000]\tvalid_set's l1: 141.329\n",
      "[3000]\tvalid_set's l1: 140.861\n",
      "[1000]\tvalid_set's l1: 154.626\n",
      "[2000]\tvalid_set's l1: 151.999\n",
      "[3000]\tvalid_set's l1: 151.125\n",
      "[4000]\tvalid_set's l1: 150.868\n",
      "[5000]\tvalid_set's l1: 150.924\n",
      "[6000]\tvalid_set's l1: 150.975\n",
      "[1000]\tvalid_set's l1: 156.167\n",
      "[2000]\tvalid_set's l1: 153.065\n",
      "[3000]\tvalid_set's l1: 151.805\n",
      "[4000]\tvalid_set's l1: 151.138\n",
      "[5000]\tvalid_set's l1: 150.772\n",
      "[6000]\tvalid_set's l1: 150.68\n",
      "[7000]\tvalid_set's l1: 150.585\n",
      "[8000]\tvalid_set's l1: 150.493\n",
      "[9000]\tvalid_set's l1: 150.575\n",
      "[10000]\tvalid_set's l1: 150.679\n",
      "[1000]\tvalid_set's l1: 159.523\n",
      "[2000]\tvalid_set's l1: 154.775\n",
      "[3000]\tvalid_set's l1: 153.311\n",
      "[4000]\tvalid_set's l1: 152.787\n",
      "[5000]\tvalid_set's l1: 152.434\n",
      "[6000]\tvalid_set's l1: 152.384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-149.1997\t = Validation score   (-mean_absolute_error)\n",
      "\t165.81s\t = Training   runtime\n",
      "\t7.38s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1/T1 ...\n",
      "\tFitting 7 child models (S1F2 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-148.7736\t = Validation score   (-mean_absolute_error)\n",
      "\t524.96s\t = Training   runtime\n",
      "\t0.38s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1/T2 ...\n",
      "\tFitting 7 child models (S1F2 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-146.2259\t = Validation score   (-mean_absolute_error)\n",
      "\t511.7s\t = Training   runtime\n",
      "\t0.23s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1/T3 ...\n",
      "\tFitting 7 child models (S1F2 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-154.5445\t = Validation score   (-mean_absolute_error)\n",
      "\t1464.62s\t = Training   runtime\n",
      "\t2.3s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-137.6912\t = Validation score   (-mean_absolute_error)\n",
      "\t0.34s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Excluded Model Types: ['FASTAI', 'KNN', 'RF', 'XGB']\n",
      "Fitting 3 L2 models ...\n",
      "Hyperparameter tuning model: LightGBMXT_BAG_L2 ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e4ef793477e403a9dbea066980425ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitted model: LightGBMXT_BAG_L2/T1 ...\n",
      "\t-137.3028\t = Validation score   (-mean_absolute_error)\n",
      "\t0.85s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitted model: LightGBMXT_BAG_L2/T2 ...\n",
      "\t-138.2441\t = Validation score   (-mean_absolute_error)\n",
      "\t1.75s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitted model: LightGBMXT_BAG_L2/T3 ...\n",
      "\t-139.2613\t = Validation score   (-mean_absolute_error)\n",
      "\t1.95s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Hyperparameter tuning model: ExtraTrees_BAG_L2 ...\n",
      "\tNo hyperparameter search space specified for ExtraTrees. Skipping HPO. Will train one model based on the provided hyperparameters.\n",
      "Warning: Exception caused ExtraTrees_BAG_L2 to fail during hyperparameter tuning... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1380, in _train_single_full\n",
      "    hpo_models, hpo_results = model.hyperparameter_tune(\n",
      "  File \"/usr/local/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1001, in hyperparameter_tune\n",
      "    return self._hyperparameter_tune(hpo_executor=hpo_executor, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 182, in _hyperparameter_tune\n",
      "    return super()._hyperparameter_tune(X=X, y=y, k_fold=k_fold, hpo_executor=hpo_executor, preprocess_kwargs=preprocess_kwargs, **kwargs)\n",
      "  File \"/usr/local/lib/python3.9/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 1080, in _hyperparameter_tune\n",
      "    model_path = model_info['path']\n",
      "TypeError: string indices must be integers\n",
      "string indices must be integers\n",
      "Hyperparameter tuning model: NeuralNetTorch_BAG_L2 ...\n",
      "Fitted model: NeuralNetTorch_BAG_L2/T1 ...\n",
      "\t-136.8727\t = Validation score   (-mean_absolute_error)\n",
      "\t35.76s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitted model: NeuralNetTorch_BAG_L2/T2 ...\n",
      "\t-131.7023\t = Validation score   (-mean_absolute_error)\n",
      "\t51.5s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitted model: NeuralNetTorch_BAG_L2/T3 ...\n",
      "\t-131.1742\t = Validation score   (-mean_absolute_error)\n",
      "\t147.86s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L2/T1 ...\n",
      "\tFitting 7 child models (S1F2 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-144.6721\t = Validation score   (-mean_absolute_error)\n",
      "\t10.2s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L2/T2 ...\n",
      "\tFitting 7 child models (S1F2 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l1: 147.409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-145.4989\t = Validation score   (-mean_absolute_error)\n",
      "\t16.78s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L2/T3 ...\n",
      "\tFitting 7 child models (S1F2 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-145.8247\t = Validation score   (-mean_absolute_error)\n",
      "\t12.19s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2/T1 ...\n",
      "\tFitting 7 child models (S1F2 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-143.0367\t = Validation score   (-mean_absolute_error)\n",
      "\t212.09s\t = Training   runtime\n",
      "\t0.36s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2/T2 ...\n",
      "\tFitting 7 child models (S1F2 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-140.9164\t = Validation score   (-mean_absolute_error)\n",
      "\t263.3s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2/T3 ...\n",
      "\tFitting 7 child models (S1F2 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t-146.5638\t = Validation score   (-mean_absolute_error)\n",
      "\t444.36s\t = Training   runtime\n",
      "\t0.27s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t-138.8287\t = Validation score   (-mean_absolute_error)\n",
      "\t0.33s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 3641.62s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221028_023652/\")\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor(label = label_reg, eval_metric = metric_reg)\n",
    "hyperparameters = {\n",
    " 'NN_TORCH': {},\n",
    " 'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}],\n",
    " 'XT':{}\n",
    "}\n",
    "\n",
    "time_limit = 30*60  # train various models for ~5 min\n",
    "num_trials = 3  # try at most 3 different hyperparameter configurations for each type of model\n",
    "search_strategy = 'auto'  # to tune hyperparameters using random search routine with a local scheduler\n",
    "\n",
    "hyperparameter_tune_kwargs = {  # HPO is not performed unless hyperparameter_tune_kwargs is specified\n",
    "    'num_trials': num_trials,\n",
    "    'scheduler' : 'local',\n",
    "    'searcher': search_strategy,\n",
    "}\n",
    "\n",
    "excluded_model_types = ['FASTAI', 'KNN', 'RF', 'XGB']\n",
    "predictor_reg = predictor.fit(combined, excluded_model_types = excluded_model_types\n",
    ",hyperparameters=hyperparameters\n",
    ",hyperparameter_tune_kwargs=hyperparameter_tune_kwargs, presets='best_quality'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NN_TORCH': {},\n",
       " 'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}],\n",
       " 'XT': {}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#/Users/nishita/Documents/Semester 1/CS5228/project/notebooks/AutogluonModels/ag-20221027_054028\n",
    "#This is with train and valid split data, with best_quality preset.\n",
    "#folderName = \"AutogluonModels/ag-20221028_001415/\"\n",
    "#This is with all of the training data available and with psf_bbox in float instead of int, results should be better slightly\n",
    "folderName = \"AutogluonModels/ag-20221028_023652/\"\n",
    "predictor = TabularPredictor.load(folderName)\n",
    "predictor.fit_hyperparameters_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: mean_absolute_error on test data: -104.54879893310817\n",
      "\tNote: Scores are always higher_is_better. This metric score can be multiplied by -1 to get the metric value.\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"mean_absolute_error\": -104.54879893310817,\n",
      "    \"root_mean_squared_error\": -212.52178955124276,\n",
      "    \"mean_squared_error\": -45165.51103406272,\n",
      "    \"r2\": 0.9508637819070908,\n",
      "    \"pearsonr\": 0.9751752886937128,\n",
      "    \"median_absolute_error\": -53.01186699478194\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_absolute_error': -104.54879893310817,\n",
       " 'root_mean_squared_error': -212.52178955124276,\n",
       " 'mean_squared_error': -45165.51103406272,\n",
       " 'r2': 0.9508637819070908,\n",
       " 'pearsonr': 0.9751752886937128,\n",
       " 'median_absolute_error': -53.01186699478194}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.evaluate(valid_data_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                       model   score_val  pred_time_val     fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0        WeightedEnsemble_L2 -137.691185       7.504357  2641.846519                0.000802           0.338653            2       True          7\n",
      "1        WeightedEnsemble_L3 -138.828713      16.098094  3754.387172                0.000736           0.331317            3       True         14\n",
      "2   NeuralNetTorch_BAG_L2/T2 -140.916443      15.091498  3070.618042                0.207525         263.295259            2       True         12\n",
      "3   NeuralNetTorch_BAG_L2/T1 -143.036661      15.242933  3019.410966                0.358960         212.088183            2       True         11\n",
      "4       LightGBMXT_BAG_L2/T1 -144.672149      15.056707  2817.525470                0.172734          10.202686            2       True          8\n",
      "5       LightGBMXT_BAG_L1/T2 -145.368549       1.340513    60.481916                1.340513          60.481916            1       True          2\n",
      "6       LightGBMXT_BAG_L2/T2 -145.498902      15.092833  2824.107074                0.208860          16.784290            2       True          9\n",
      "7       LightGBMXT_BAG_L2/T3 -145.824681      15.091993  2819.515344                0.208020          12.192560            2       True         10\n",
      "8   NeuralNetTorch_BAG_L1/T2 -146.225938       0.230800   511.704076                0.230800         511.704076            1       True          5\n",
      "9   NeuralNetTorch_BAG_L2/T3 -146.563779      15.149279  3251.685437                0.265306         444.362654            2       True         13\n",
      "10      LightGBMXT_BAG_L1/T1 -147.587589       3.253439    79.738326                3.253439          79.738326            1       True          1\n",
      "11  NeuralNetTorch_BAG_L1/T1 -148.773638       0.381490   524.961832                0.381490         524.961832            1       True          4\n",
      "12      LightGBMXT_BAG_L1/T3 -149.199672       7.380418   165.814918                7.380418         165.814918            1       True          3\n",
      "13  NeuralNetTorch_BAG_L1/T3 -154.544475       2.297312  1464.621717                2.297312        1464.621717            1       True          6\n",
      "Number of models trained: 14\n",
      "Types of models trained:\n",
      "{'StackerEnsembleModel_TabularNeuralNetTorch', 'WeightedEnsembleModel', 'StackerEnsembleModel_LGB'}\n",
      "Bagging used: True  (with 8 folds)\n",
      "Multi-layer stack-ensembling used: True  (with 3 levels)\n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('float', [])     : 15 | ['num_beds', 'num_baths', 'built_year', 'pri_sch', 'sec_sch', ...]\n",
      "('int', [])       :  2 | ['close_pri_sch', 'close_sec_sch']\n",
      "('int', ['bool']) : 14 | ['property_type_cluster house', 'property_type_condo', 'property_type_corner terrace', 'property_type_executive condo', 'property_type_hdb', ...]\n",
      "Plot summary of models saved to file: AutogluonModels/ag-20221028_023652/SummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    }
   ],
   "source": [
    "#With target encoding and less one hot encoding.\n",
    "predictor = TabularPredictor.load(folderName)\n",
    "results = predictor.fit_summary(show_plot=True)\n",
    "\n",
    "def writePredictionsToFile(modelName, filename, folder = folderName, refit = False):\n",
    "    if(refit == True):\n",
    "        modelName = modelName +  '_FULL'    \n",
    "    y_pred = predictor.predict(test_data_reg, model=modelName)\n",
    "    yTest = y_pred * df_test_size_sqft\n",
    "    yTest = pd.DataFrame(yTest, columns=['Predicted'], index=df_test.index)\n",
    "    yTest.to_csv(f'{folder}/predictions/{filename}.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       model  score_test   score_val  pred_time_test  pred_time_val     fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0       LightGBMXT_BAG_L1/T2  -91.154465 -145.368549        2.270393       1.340513    60.481916                 2.270393                1.340513          60.481916            1       True          2\n",
      "1       LightGBMXT_BAG_L1/T1 -102.339094 -147.587589        5.158992       3.253439    79.738326                 5.158992                3.253439          79.738326            1       True          1\n",
      "2   NeuralNetTorch_BAG_L2/T2 -103.128439 -140.916443       20.328937      15.091498  3070.618042                 0.296184                0.207525         263.295259            2       True         12\n",
      "3        WeightedEnsemble_L2 -104.548799 -137.691185       11.549747       7.504357  2641.846519                 0.005994                0.000802           0.338653            2       True          7\n",
      "4        WeightedEnsemble_L3 -104.555367 -138.828713       21.679346      16.098094  3754.387172                 0.004287                0.000736           0.331317            3       True         14\n",
      "5       LightGBMXT_BAG_L1/T3 -104.772158 -149.199672        8.489000       7.380418   165.814918                 8.489000                7.380418         165.814918            1       True          3\n",
      "6   NeuralNetTorch_BAG_L2/T1 -105.821291 -143.036661       20.547576      15.242933  3019.410966                 0.514823                0.358960         212.088183            2       True         11\n",
      "7   NeuralNetTorch_BAG_L2/T3 -108.616067 -146.563779       20.473411      15.149279  3251.685437                 0.440658                0.265306         444.362654            2       True         13\n",
      "8       LightGBMXT_BAG_L2/T2 -112.583008 -145.498902       20.258854      15.092833  2824.107074                 0.226101                0.208860          16.784290            2       True          9\n",
      "9   NeuralNetTorch_BAG_L1/T2 -113.479899 -146.225938        0.277830       0.230800   511.704076                 0.277830                0.230800         511.704076            1       True          5\n",
      "10      LightGBMXT_BAG_L2/T1 -115.122056 -144.672149       20.197294      15.056707  2817.525470                 0.164541                0.172734          10.202686            2       True          8\n",
      "11      LightGBMXT_BAG_L2/T3 -116.201568 -145.824681       20.204051      15.091993  2819.515344                 0.171298                0.208020          12.192560            2       True         10\n",
      "12  NeuralNetTorch_BAG_L1/T1 -119.491812 -148.773638        0.507851       0.381490   524.961832                 0.507851                0.381490         524.961832            1       True          4\n",
      "13  NeuralNetTorch_BAG_L1/T3 -131.332232 -154.544475        3.328687       2.297312  1464.621717                 3.328687                2.297312        1464.621717            1       True          6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: mean_absolute_error on test data: -104.54879893310817\n",
      "\tNote: Scores are always higher_is_better. This metric score can be multiplied by -1 to get the metric value.\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"mean_absolute_error\": -104.54879893310817,\n",
      "    \"root_mean_squared_error\": -212.52178955124276,\n",
      "    \"mean_squared_error\": -45165.51103406272,\n",
      "    \"r2\": 0.9508637819070908,\n",
      "    \"pearsonr\": 0.9751752886937128,\n",
      "    \"median_absolute_error\": -53.01186699478194\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_absolute_error': -104.54879893310817,\n",
       " 'root_mean_squared_error': -212.52178955124276,\n",
       " 'mean_squared_error': -45165.51103406272,\n",
       " 'r2': 0.9508637819070908,\n",
       " 'pearsonr': 0.9751752886937128,\n",
       " 'median_absolute_error': -53.01186699478194}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(valid_data_reg)\n",
    "predictor.evaluate(valid_data_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "writePredictionsToFile(modelName = 'LightGBMXT_BAG_L1/T2', filename = 'LightGBMXT_BAG_L1_T2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "writePredictionsToFile(modelName = 'NeuralNetTorch_BAG_L2/T2', filename = 'NeuralNetTorch_BAG_L2_T2')\n",
    "#writePredictionsToFile('RandomForestMSE')\n",
    "#writePredictionsToFile('LightGBMLarge')\n",
    "writePredictionsToFile(modelName = 'WeightedEnsemble_L2', filename = 'WeightedEnsemble_L2')\n",
    "##writePredictionsToFile('XGBoost')\n",
    "#writePredictionsToFile(modelName = 'ExtraTreesMSE', filename = 'ExtraTreesMSE')\n",
    "#writePredictionsToFile('LGBModel')\n",
    "#writePredictionsToFile(modelName = 'LightGBMXT_BAG_L2/T2', filename = 'LightGBMXT')\n",
    "#writePredictionsToFile(modelName = 'NeuralNetTorch/a2acf_00004', filename = 'NeuralNetTorch')\n",
    "#writePredictionsToFile('NeuralNetFastAI')\n",
    "#writePredictionsToFile('KNeighborsDist')\n",
    "##writePredictionsToFile('KNeighborsUnif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictor.refit_full()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelName = 'CatBoost_BAG_L2/T3'\n",
    "y_pred = predictor.predict(valid_data_reg, model=modelName)\n",
    "yTest = y_pred * valid['size_sqft']\n",
    "yTest = pd.DataFrame(yTest, columns=['Predicted'], index=valid.index)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yTest.to_csv(f'../predictions/valid_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yTest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = valid['price']\n",
    "pred = yTest['Predicted']\n",
    "\n",
    "valid_error = mean_squared_error(actual, pred, squared=False)\n",
    "    #print(modelName)\n",
    "print(f\"RMSE: {valid_error}\")\n",
    "print(f'Percentage error for validation data {((abs(pred - actual)/actual)*100).mean()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "e3674cc7966855886e325525ebdd8373c9ba83162eba59918954002e59074a83"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
