{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "#warnings.filterwarnings(action='once')\n",
    "import pandas as pd\n",
    "from pandas import MultiIndex, Int16Dtype\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, f1_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV, PredefinedSplit\n",
    "# models\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.svm import LinearSVR\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn import ensemble\n",
    "from sklearn import datasets\n",
    "from sklearn import model_selection\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install xgboost --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train = pd.read_csv('../data/train_encoded_pca_cum.csv')\n",
    "#df_test = pd.read_csv('../data/test_encoded_pca_cum.csv')\n",
    "#df_train = pd.read_csv('../data/train_encoded_pca.csv')\n",
    "#df_test = pd.read_csv('../data/test_encoded_pca.csv')\n",
    "\n",
    "df_train = pd.read_csv('../data/train_encoded_1.csv')\n",
    "df_test = pd.read_csv('../data/test_encoded_1.csv')\n",
    "df_test = df_test.reindex(columns=df_train.columns.intersection(df_test.columns))\n",
    "\n",
    "#train_encoded_pca_cum\n",
    "#train_encoded_pca\n",
    "#ex = pd.read_csv('../data/example-submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, valid = train_test_split(df_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train.drop(['price', 'price_per_sqft'], axis=1)\n",
    "y_train = train['price_per_sqft']\n",
    "\n",
    "X_valid = valid.drop(['price', 'price_per_sqft'], axis=1)\n",
    "y_valid = valid['price_per_sqft']\n",
    "\n",
    "df_test_size_sqft = df_test['size_sqft'].copy()\n",
    "#df_test= df_test.drop(['size_sqft'], axis=1)\n",
    "\n",
    "np.random.seed(0)\n",
    "idxs = np.arange(X_train.shape[0])\n",
    "np.random.shuffle(idxs)\n",
    "df_test.columns.difference(X_train.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/usr/local/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/usr/local/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/usr/local/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/usr/local/lib/python3.9/site-packages/xgboost/compat.py:31: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/usr/local/lib/python3.9/site-packages/xgboost/compat.py:31: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/usr/local/lib/python3.9/site-packages/xgboost/compat.py:31: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/usr/local/lib/python3.9/site-packages/xgboost/compat.py:31: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/usr/local/lib/python3.9/site-packages/xgboost/data.py:208: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/usr/local/lib/python3.9/site-packages/xgboost/data.py:208: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/usr/local/lib/python3.9/site-packages/xgboost/data.py:208: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/usr/local/lib/python3.9/site-packages/xgboost/data.py:208: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:26:04] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:573: \n",
      "Parameters: { \"max_depth\", \"num_parallel_tree\", \"subsample\", \"verbose_eval\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:26:04] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:573: \n",
      "Parameters: { \"max_depth\", \"num_parallel_tree\", \"subsample\", \"verbose_eval\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:26:04] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:573: \n",
      "Parameters: { \"max_depth\", \"num_parallel_tree\", \"subsample\", \"verbose_eval\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:26:04] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:573: \n",
      "Parameters: { \"max_depth\", \"num_parallel_tree\", \"subsample\", \"verbose_eval\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[21:26:15] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:573: \n",
      "Parameters: { \"max_depth\", \"num_parallel_tree\", \"subsample\", \"verbose_eval\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Training RMSE: 412.212\n",
      "Test RMSE: 410.929\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "xgb_model = xgb.XGBRegressor(eval_metric=[\"error\"], verbose_eval=50, seed =42)\n",
    "\n",
    "parameters = {'nthread':[4], #when use hyperthread, xgboost may become slower\n",
    "              'objective':['reg:squarederror'],\n",
    "              'learning_rate': [0.05], #so called `eta` value\n",
    "              'max_depth': [2, 3],\n",
    "              'subsample': [0.7],\n",
    "              'n_estimators': [3000],\n",
    "              #'reg_alpha':[0.01],\n",
    "              #'reg_lambda': [0.01],\n",
    "              'num_parallel_tree':[6],\n",
    "              'booster': ['gblinear'], \n",
    "              'eval_metric': [[\"error\"]], \n",
    "              'verbose_eval': [50],\n",
    "                'seed' :[42]}\n",
    "#{'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 7, 'min_child_weight': 12, 'n_estimators': 1000, 'nthread': 4, \n",
    "# 'objective': 'reg:squarederror', 'subsample': 0.7}\n",
    "#3217243.53476 on Kaggle\n",
    "\n",
    "#3.\n",
    "#{'booster': 'gblinear', 'colsample_bytree': 0.7, 'grow_policy': 1, 'learning_rate': 0.05, 'max_depth': 7, 'min_child_weight': 12, 'n_estimators': 1200, 'nthread': 4, \n",
    "# 'num_parallel_tree': 3, 'objective': 'reg:squarederror', 'reg_alpha': 0.1, 'reg_lambda': 0.1, 'subsample': 0.7}\n",
    "#score -887\n",
    "\n",
    "#3\n",
    "#{'booster': 'gblinear', 'colsample_bytree': 0.7, 'grow_policy': 1, 'learning_rate': 0.05, 'max_depth': 2, 'min_child_weight': 12, 'n_estimators': 1500, 'nthread': 4,\n",
    "#  'num_parallel_tree': 3, 'objective': 'reg:squarederror', 'reg_alpha': 0.05, 'reg_lambda': 0.05, 'subsample': 0.7}\n",
    "# - 878\n",
    "\n",
    "#4\n",
    "#{'booster': 'gblinear', 'grow_policy': 1, 'learning_rate': 0.05, 'max_depth': 2, \n",
    "# 'n_estimators': 2500, 'nthread': 4, 'num_parallel_tree': 3, 'objective': 'reg:squarederror', \n",
    "# 'reg_alpha': 0.01, 'reg_lambda': 0.01, 'subsample': 0.7}\n",
    "#score -838\n",
    "\n",
    "#5\n",
    "#{'booster': 'gblinear', 'grow_policy': 0, 'learning_rate': 0.05, 'max_depth': 2, 'n_estimators': 5000, \n",
    "# 'nthread': 4, 'num_parallel_tree': 3, 'objective': 'reg:squarederror', 'reg_alpha': 0.01, 'reg_lambda': 0.01, '\n",
    "# subsample': 0.7}\n",
    "#-888\n",
    "\n",
    "\n",
    "clf = GridSearchCV(xgb_model, parameters, n_jobs=5, \n",
    "                   cv=KFold(n_splits=2, shuffle=True, random_state=42), \n",
    "                   scoring='neg_root_mean_squared_error',\n",
    "                   verbose=0, refit=True)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "yt_pred = clf.predict(X_train)\n",
    "yv_pred = clf.predict(X_valid)\n",
    "\n",
    "print('Training RMSE: {:.3f}'.format(mean_squared_error(yt_pred, y_train, squared=False)))\n",
    "print('Test RMSE: {:.3f}'.format(mean_squared_error(yv_pred, y_valid, squared=False)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'booster': 'gblinear', 'eval_metric': ['error'], 'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 3000, 'nthread': 4, 'num_parallel_tree': 6, 'objective': 'reg:squarederror', 'seed': 42, 'subsample': 0.7, 'verbose_eval': 50}\n",
      "XGBRegressor(base_score=0.5, booster='gblinear', colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=None,\n",
      "             eval_metric=['error'], gamma=None, gpu_id=-1,\n",
      "             importance_type='gain', interaction_constraints=None,\n",
      "             learning_rate=0.05, max_delta_step=None, max_depth=3,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=3000, n_jobs=4, nthread=4, num_parallel_tree=6,\n",
      "             random_state=42, reg_alpha=0, reg_lambda=0, scale_pos_weight=1,\n",
      "             seed=42, subsample=0.7, tree_method=None, validate_parameters=1,\n",
      "             verbose_eval=50, verbosity=None)\n",
      "-415.3796196642709\n",
      "[1731.4954 2317.2336 2310.2014 ... 2460.2104  746.9792 1609.5659]\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_params_)\n",
    "\n",
    "print(clf.best_estimator_)\n",
    "\n",
    "print(clf.best_score_)\n",
    "\n",
    "print(clf.predict(df_test.copy()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "yTest = clf.predict(df_test)\n",
    "\n",
    "yTest = yTest * df_test_size_sqft\n",
    "yTest = pd.DataFrame(yTest.values, columns=['Predicted'], index=df_test.index)\n",
    "\n",
    "yTest.to_csv('../predictions/xgboost_grid_search_13.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler = preprocessing.MinMaxScaler().fit(X_train)\n",
    "\n",
    "# xgb_model = xgb.XGBRegressor(objective=\"reg:squarederror\", random_state=42, eval_metric=[\"error\"])\n",
    "# xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# # Predict labels for test data\n",
    "# yt_pred = xgb_model.predict(X_train)\n",
    "# yv_pred = xgb_model.predict(X_valid)\n",
    "\n",
    "# print('Training RMSE: {:.3f}'.format(mean_squared_error(yt_pred, y_train, squared=False)))\n",
    "# print('Test RMSE: {:.3f}'.format(mean_squared_error(yv_pred, y_valid, squared=False)))\n",
    "\n",
    "# print(f'Percentage error for training data {((abs(yt_pred - y_train)/y_train)*100).mean()}')\n",
    "# print(f'Percentage error for validation data {((abs(yv_pred - y_valid)/y_valid)*100).mean()}')\n",
    "\n",
    "# xgb.plot_importance(xgb_model, height = 5, max_num_features=20)\n",
    "\n",
    "# score = cross_val_score(xgb_model, X_train, y_train, n_jobs=-1, cv=5, scoring=\"r2\")\n",
    "# r2_mean = score.mean()\n",
    "\n",
    "# print(f\"R2 mean: {r2_mean}\")\n",
    "#yTest = xgb_model.predict(df_test)\n",
    "\n",
    "# yTest = yTest * df_test_size_sqft\n",
    "# yTest = pd.DataFrame(yTest.values, columns=['Predicted'], index=df_test.index)\n",
    "\n",
    "# yTest.to_csv('../predictions/xgboost.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
