{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/32/zv3nm8_12xb9ytd7vk7nnr6w0000gn/T/ipykernel_90799/2656712151.py:8: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, f1_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV, PredefinedSplit\n",
    "from pandas import MultiIndex, Int64Index\n",
    "# models\n",
    "\n",
    "import optuna\n",
    "import pandas as pd\n",
    "from sklearn import ensemble\n",
    "from sklearn import datasets\n",
    "from sklearn import model_selection\n",
    "\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "import autogluon.core as ag\n",
    "from sklearn.model_selection import train_test_split\n",
    "import bokeh\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install xgboost\n",
    "#!pip3 install optuna\n",
    "#!pip install autogluon --upgrade\n",
    "# !pip install optuna\n",
    "# !pip install scipy\n",
    "# !pip install autogluon\n",
    "# !pip install xgboost\n",
    "# !python3.9 -m pip install --upgrade pip\n",
    "#!pip install bokeh==2.0.1\n",
    "#!pip install jupyter --upgrade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../data/train_encoded_1.csv')\n",
    "df_test = pd.read_csv('../data/test_encoded_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "train, valid = train_test_split(df_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = df_train.drop(['price', 'size_sqft'], axis=1)\n",
    "X_train = train.drop(['price', 'size_sqft'], axis=1)\n",
    "\n",
    "X_valid = valid.drop(['price', 'size_sqft'], axis=1)\n",
    "y_valid = valid['price_per_sqft']\n",
    "\n",
    "df_test_size_sqft = df_test['size_sqft'].copy()\n",
    "df_test= df_test.drop(['size_sqft'], axis=1)\n",
    "\n",
    "metric_reg = 'mean_absolute_error'\n",
    "label_reg = 'price_per_sqft'\n",
    "train_data_reg = TabularDataset(X_train) \n",
    "valid_data_reg = TabularDataset(X_valid)\n",
    "test_data_reg = TabularDataset(df_test)\n",
    "combined = TabularDataset(combined)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tabular Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"Autogluon_plain/\"\n",
      "AutoGluon Version:  0.5.2\n",
      "Python Version:     3.9.7\n",
      "Operating System:   Darwin\n",
      "Train Data Rows:    20147\n",
      "Train Data Columns: 31\n",
      "Label Column: price_per_sqft\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (4486.890450010187, 447.8293983244478, 1719.76428, 982.28364)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    5774.22 MB\n",
      "\tTrain Data (Original)  Memory Usage: 5.0 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 14 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 15 | ['num_beds', 'num_baths', 'built_year', 'pri_sch', 'sec_sch', ...]\n",
      "\t\t('int', [])   : 16 | ['close_pri_sch', 'close_sec_sch', 'property_type_cluster house', 'property_type_condo', 'property_type_corner terrace', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 15 | ['num_beds', 'num_baths', 'built_year', 'pri_sch', 'sec_sch', ...]\n",
      "\t\t('int', [])       :  2 | ['close_pri_sch', 'close_sec_sch']\n",
      "\t\t('int', ['bool']) : 14 | ['property_type_cluster house', 'property_type_condo', 'property_type_corner terrace', 'property_type_executive condo', 'property_type_hdb', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t31 features in original data used to generate 31 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 3.02 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.16s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 18132, Val Rows: 2015\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-169.4892\t = Validation score   (-mean_absolute_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t1.26s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-152.5521\t = Validation score   (-mean_absolute_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t1.26s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l1: 142.873\n",
      "[2000]\tvalid_set's l1: 140.912\n",
      "[3000]\tvalid_set's l1: 140.689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-140.5774\t = Validation score   (-mean_absolute_error)\n",
      "\t3.69s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's l1: 140.175\n",
      "[2000]\tvalid_set's l1: 138.914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-138.8473\t = Validation score   (-mean_absolute_error)\n",
      "\t2.43s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-134.0851\t = Validation score   (-mean_absolute_error)\n",
      "\t6.7s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-134.8971\t = Validation score   (-mean_absolute_error)\n",
      "\t162.45s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-132.1399\t = Validation score   (-mean_absolute_error)\n",
      "\t3.26s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t-149.7377\t = Validation score   (-mean_absolute_error)\n",
      "\t21.2s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "/Users/nishita/miniconda3/lib/python3.9/site-packages/xgboost/sklearn.py:793: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "/Users/nishita/miniconda3/lib/python3.9/site-packages/xgboost/sklearn.py:793: UserWarning: `callbacks` in `fit` method is deprecated for better compatibility with scikit-learn, use `callbacks` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\t-137.0248\t = Validation score   (-mean_absolute_error)\n",
      "\t3.28s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-139.6101\t = Validation score   (-mean_absolute_error)\n",
      "\t63.34s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t-133.672\t = Validation score   (-mean_absolute_error)\n",
      "\t2.98s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-128.2193\t = Validation score   (-mean_absolute_error)\n",
      "\t0.36s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 274.43s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"Autogluon_plain/\")\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor(label = label_reg, eval_metric = metric_reg, path = 'Autogluon_plain')\n",
    "predictor_reg = predictor.fit(combined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NN_TORCH': {},\n",
       " 'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}},\n",
       "  {},\n",
       "  'GBMLarge'],\n",
       " 'CAT': {},\n",
       " 'XGB': {},\n",
       " 'FASTAI': {},\n",
       " 'RF': [{'criterion': 'gini',\n",
       "   'ag_args': {'name_suffix': 'Gini',\n",
       "    'problem_types': ['binary', 'multiclass']}},\n",
       "  {'criterion': 'entropy',\n",
       "   'ag_args': {'name_suffix': 'Entr',\n",
       "    'problem_types': ['binary', 'multiclass']}},\n",
       "  {'criterion': 'squared_error',\n",
       "   'ag_args': {'name_suffix': 'MSE',\n",
       "    'problem_types': ['regression', 'quantile']}}],\n",
       " 'XT': [{'criterion': 'gini',\n",
       "   'ag_args': {'name_suffix': 'Gini',\n",
       "    'problem_types': ['binary', 'multiclass']}},\n",
       "  {'criterion': 'entropy',\n",
       "   'ag_args': {'name_suffix': 'Entr',\n",
       "    'problem_types': ['binary', 'multiclass']}},\n",
       "  {'criterion': 'squared_error',\n",
       "   'ag_args': {'name_suffix': 'MSE',\n",
       "    'problem_types': ['regression', 'quantile']}}],\n",
       " 'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}},\n",
       "  {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#/Users/nishita/Documents/Semester 1/CS5228/project/notebooks/AutogluonModels/ag-20221027_054028\n",
    "folderName = \"Autogluon_plain/\"\n",
    "predictor = TabularPredictor.load(folderName)\n",
    "predictor.fit_hyperparameters_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: mean_absolute_error on test data: -109.27624442550133\n",
      "\tNote: Scores are always higher_is_better. This metric score can be multiplied by -1 to get the metric value.\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"mean_absolute_error\": -109.27624442550133,\n",
      "    \"root_mean_squared_error\": -220.83813362474177,\n",
      "    \"mean_squared_error\": -48769.481262859365,\n",
      "    \"r2\": 0.9505668121922949,\n",
      "    \"pearsonr\": 0.9749931626958129,\n",
      "    \"median_absolute_error\": -53.19999999999999\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_absolute_error': -109.27624442550133,\n",
       " 'root_mean_squared_error': -220.83813362474177,\n",
       " 'mean_squared_error': -48769.481262859365,\n",
       " 'r2': 0.9505668121922949,\n",
       " 'pearsonr': 0.9749931626958129,\n",
       " 'median_absolute_error': -53.19999999999999}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.evaluate(valid_data_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                  model   score_val  pred_time_val    fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0   WeightedEnsemble_L2 -128.219325       1.420413  232.412809                0.002624           0.360921            2       True         12\n",
      "1         ExtraTreesMSE -132.139915       0.076599    3.255411                0.076599           3.255411            1       True          7\n",
      "2         LightGBMLarge -133.672026       0.039147    2.980504                0.039147           2.980504            1       True         11\n",
      "3       RandomForestMSE -134.085114       0.078687    6.702206                0.078687           6.702206            1       True          5\n",
      "4              CatBoost -134.897091       0.010550  162.453468                0.010550         162.453468            1       True          6\n",
      "5               XGBoost -137.024765       0.047590    3.279760                0.047590           3.279760            1       True          9\n",
      "6              LightGBM -138.847305       0.072739    2.431708                0.072739           2.431708            1       True          4\n",
      "7        NeuralNetTorch -139.610070       0.030752   63.338314                0.030752          63.338314            1       True         10\n",
      "8            LightGBMXT -140.577404       0.079568    3.685585                0.079568           3.685585            1       True          3\n",
      "9       NeuralNetFastAI -149.737735       0.049803   21.195497                0.049803          21.195497            1       True          8\n",
      "10       KNeighborsDist -152.552113       1.260741    0.024191                1.260741           0.024191            1       True          2\n",
      "11       KNeighborsUnif -169.489238       1.264939    0.013603                1.264939           0.013603            1       True          1\n",
      "Number of models trained: 12\n",
      "Types of models trained:\n",
      "{'CatBoostModel', 'RFModel', 'XGBoostModel', 'TabularNeuralNetTorchModel', 'NNFastAiTabularModel', 'KNNModel', 'XTModel', 'WeightedEnsembleModel', 'LGBModel'}\n",
      "Bagging used: False \n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('float', [])     : 15 | ['num_beds', 'num_baths', 'built_year', 'pri_sch', 'sec_sch', ...]\n",
      "('int', [])       :  2 | ['close_pri_sch', 'close_sec_sch']\n",
      "('int', ['bool']) : 14 | ['property_type_cluster house', 'property_type_condo', 'property_type_corner terrace', 'property_type_executive condo', 'property_type_hdb', ...]\n",
      "Plot summary of models saved to file: Autogluon_plain/SummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    }
   ],
   "source": [
    "#With target encoding and less one hot encoding.\n",
    "predictor = TabularPredictor.load(folderName)\n",
    "results = predictor.fit_summary(show_plot=True)\n",
    "\n",
    "def writePredictionsToFile(modelName, filename, folder = folderName, refit = False):\n",
    "    if(refit == True):\n",
    "        modelName = modelName +  '_FULL'    \n",
    "    y_pred = predictor.predict(test_data_reg, model=modelName)\n",
    "    yTest = y_pred * df_test_size_sqft\n",
    "    yTest = pd.DataFrame(yTest, columns=['Predicted'], index=df_test.index)\n",
    "    yTest.to_csv(f'{folder}/predictions/{filename}.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  model  score_test   score_val  pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0         ExtraTreesMSE -108.024002 -132.139915        0.446296       0.076599    3.255411                 0.446296                0.076599           3.255411            1       True          7\n",
      "1       RandomForestMSE -109.164822 -134.085114        0.419242       0.078687    6.702206                 0.419242                0.078687           6.702206            1       True          5\n",
      "2   WeightedEnsemble_L2 -109.276244 -128.219325        3.257599       1.420413  232.412809                 0.022486                0.002624           0.360921            2       True         12\n",
      "3              CatBoost -110.617249 -134.897091        0.030922       0.010550  162.453468                 0.030922                0.010550         162.453468            1       True          6\n",
      "4         LightGBMLarge -111.397338 -133.672026        0.131881       0.039147    2.980504                 0.131881                0.039147           2.980504            1       True         11\n",
      "5               XGBoost -112.233275 -137.024765        0.093405       0.047590    3.279760                 0.093405                0.047590           3.279760            1       True          9\n",
      "6        KNeighborsDist -115.930499 -152.552113        2.544157       1.260741    0.024191                 2.544157                1.260741           0.024191            1       True          2\n",
      "7              LightGBM -119.576178 -138.847305        0.169679       0.072739    2.431708                 0.169679                0.072739           2.431708            1       True          4\n",
      "8            LightGBMXT -126.016919 -140.577404        0.187959       0.079568    3.685585                 0.187959                0.079568           3.685585            1       True          3\n",
      "9        NeuralNetTorch -129.206055 -139.610070        0.081857       0.030752   63.338314                 0.081857                0.030752          63.338314            1       True         10\n",
      "10      NeuralNetFastAI -145.260356 -149.737735        0.121272       0.049803   21.195497                 0.121272                0.049803          21.195497            1       True          8\n",
      "11       KNeighborsUnif -156.349051 -169.489238        2.425669       1.264939    0.013603                 2.425669                1.264939           0.013603            1       True          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: mean_absolute_error on test data: -109.27624442550133\n",
      "\tNote: Scores are always higher_is_better. This metric score can be multiplied by -1 to get the metric value.\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"mean_absolute_error\": -109.27624442550133,\n",
      "    \"root_mean_squared_error\": -220.83813362474177,\n",
      "    \"mean_squared_error\": -48769.481262859365,\n",
      "    \"r2\": 0.9505668121922949,\n",
      "    \"pearsonr\": 0.9749931626958129,\n",
      "    \"median_absolute_error\": -53.19999999999999\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_absolute_error': -109.27624442550133,\n",
       " 'root_mean_squared_error': -220.83813362474177,\n",
       " 'mean_squared_error': -48769.481262859365,\n",
       " 'r2': 0.9505668121922949,\n",
       " 'pearsonr': 0.9749931626958129,\n",
       " 'median_absolute_error': -53.19999999999999}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(valid_data_reg)\n",
    "predictor.evaluate(valid_data_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "writePredictionsToFile(modelName = 'WeightedEnsemble_L2', filename = 'WeightedEnsemble_L2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "writePredictionsToFile(modelName = 'CatBoost_BAG_L1/T2', filename = 'CatBoost_BAG_L1_T2')\n",
    "writePredictionsToFile(modelName = 'LightGBMXT_BAG_L1/T2', filename = 'LightGBMXT_BAG_L1_T2')\n",
    "writePredictionsToFile(modelName = 'NeuralNetTorch_BAG_L2/T2', filename = 'NeuralNetTorch_BAG_L2_T2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictor.refit_full()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "e3674cc7966855886e325525ebdd8373c9ba83162eba59918954002e59074a83"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
