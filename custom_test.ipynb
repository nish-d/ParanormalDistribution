{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(modelName, folder = \"AutogluonModels/ag-20221028_023652\") :\n",
    "    actual = pd.read_csv('data/example-submission.csv')\n",
    "    pred = pd.read_csv(f'notebooks/{folder}/predictions/{modelName}.csv')\n",
    "\n",
    "    actual = actual['Predicted']\n",
    "    pred = pred['Predicted']\n",
    "\n",
    "    valid_error = mean_squared_error(actual, pred, squared=False)\n",
    "    print(modelName)\n",
    "    print(f\"RMSE: {valid_error}\")\n",
    "    print(f'Percentage error for validation data {((abs(pred - actual)/actual)*100).mean()}')\n",
    "\n",
    "    print(\"____________________________________________________\\n\")\n",
    "\n",
    "def compare(modelName, folder1 = \"AutogluonModels/ag-20221028_001415\", folder2 = \"AutogluonModels/ag-20221028_023652\") :\n",
    "    actual = pd.read_csv('data/example-submission.csv')\n",
    "    pred1 = pd.read_csv(f'notebooks/{folder1}/predictions/{modelName}.csv')\n",
    "    pred2 = pd.read_csv(f'notebooks/{folder2}/predictions/{modelName}.csv')\n",
    "\n",
    "\n",
    "    actual = actual['Predicted']\n",
    "    pred1 = pred1['Predicted']\n",
    "    pred2 = pred2['Predicted']\n",
    "\n",
    "    valid_error1 = mean_squared_error(actual, pred1, squared=False)\n",
    "    valid_error2 = mean_squared_error(actual, pred2, squared=False)\n",
    "\n",
    "    print(modelName)\n",
    "    print(f\"RMSE 1: {valid_error1}\")\n",
    "    print(f\"RMSE 2: {valid_error2}\")\n",
    "\n",
    "    diff = valid_error2 - valid_error1\n",
    "\n",
    "    print(f'Percentage error for validation data {((abs(pred1 - actual)/actual)*100).mean()}')\n",
    "    print(f'Percentage error for validation data {((abs(pred2 - actual)/actual)*100).mean()}')\n",
    "\n",
    "    print(f'Difference in RMSE, New - Old {diff}')\n",
    "\n",
    "\n",
    "    print(\"____________________________________________________\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WeightedEnsemble_L2\n",
      "RMSE: 1711487.744096278\n",
      "Percentage error for validation data 21.62236193547503\n",
      "____________________________________________________\n",
      "\n",
      "LightGBMXT_BAG_L1_T2\n",
      "RMSE: 1722388.5218222095\n",
      "Percentage error for validation data 22.911559114373034\n",
      "____________________________________________________\n",
      "\n",
      "NeuralNetTorch_BAG_L2_T2\n",
      "RMSE: 1703985.4198694243\n",
      "Percentage error for validation data 21.521834070434785\n",
      "____________________________________________________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict('WeightedEnsemble_L2')\n",
    "predict('LightGBMXT_BAG_L1_T2')\n",
    "predict('NeuralNetTorch_BAG_L2_T2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "e3674cc7966855886e325525ebdd8373c9ba83162eba59918954002e59074a83"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
